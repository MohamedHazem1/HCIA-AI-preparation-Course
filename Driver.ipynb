{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHrYGI2rT6kuXnuSfcPXfm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"vNB65FP5njD2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"gsyDlVatmUyx","executionInfo":{"status":"error","timestamp":1724506654085,"user_tz":-180,"elapsed":343,"user":{"displayName":"Mohamed Hazem","userId":"06006868447837990830"}},"outputId":"dad1bdf3-a3f1-4b87-f3ac-2b8ba1c42c4a"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'D:\\\\Coursat\\\\NTI\\\\HCIA AI\\\\Proje\\\\Driver Drowsiness Dataset (DDD)'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b94ffd825442>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Train generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Coursat\\\\NTI\\\\HCIA AI\\\\Proje\\\\Driver Drowsiness Dataset (DDD)'"]}],"source":["import sys\n","import io\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Set UTF-8 encoding for stdout\n","# Image data generators for loading and augmenting images\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2,  # Use 20% of data for validation\n","    fill_mode='nearest'\n",")\n","\n","# Correct path to your dataset directory\n","dataset_dir = 'D:\\Coursat\\NTI\\HCIA AI\\Proje\\Driver Drowsiness Dataset (DDD)'\n","\n","# Train generator\n","train_generator = train_datagen.flow_from_directory(\n","    dataset_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","# Validation generator\n","val_generator = train_datagen.flow_from_directory(\n","    dataset_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='validation'\n",")\n","\n","# Load the VGG16 model pre-trained on ImageNet, excluding the top layers\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the convolutional base to retain pre-trained weights\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add custom top layers for drowsiness detection\n","x = base_model.output\n","x = Flatten()(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(1, activation='sigmoid')(x)  # Binary classification: 'drowsy' or 'non-drowsy'\n","\n","# Define the model\n","model = Model(inputs=base_model.input, outputs=x)\n","\n","# Compile the model with Adam optimizer and binary cross-entropy loss\n","model.compile(optimizer=Adam(learning_rate=1e-4),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Define callbacks for early stopping and model checkpointing\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","model_checkpoint = ModelCheckpoint('drowsiness_detection_vgg16.keras', save_best_only=True)\n","\n","# Callbacks list\n","callbacks = [early_stopping, model_checkpoint]"]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=2,\n","    validation_data=val_generator,\n","    callbacks=callbacks\n",")"],"metadata":{"id":"GVHw_9TWmYzz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Plot training & validation accuracy values\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n","# Evaluate the model on the validation set\n","val_loss, val_accuracy = model.evaluate(val_generator)\n","print(f'Validation Loss: {val_loss}')\n","print(f'Validation Accuracy: {val_accuracy}')"],"metadata":{"id":"Hj_CmcLEmbNs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the trained model\n","model.save('drowsiness_detection_vgg16_final.h5')"],"metadata":{"id":"g1zecR66mc0v"},"execution_count":null,"outputs":[]}]}